{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\dev\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x2c09b504df0 state=finished raised RateLimitError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\embeddings\\openai.py:147\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(list_of_text, engine)\u001b[0m\n\u001b[0;32m    145\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[1;32m--> 147\u001b[0m data \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mlist_of_text, engine\u001b[39m=\u001b[39;49mengine)\u001b[39m.\u001b[39mdata\n\u001b[0;32m    148\u001b[0m data \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(data, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m])  \u001b[39m# maintain the same order as input.\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    138\u001b[0m (\n\u001b[0;32m    139\u001b[0m     deployment_id,\n\u001b[0;32m    140\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m )\n\u001b[1;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m     url,\n\u001b[0;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    216\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m )\n\u001b[1;32m--> 226\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\openai\\api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m documents \u001b[39m=\u001b[39m SimpleDirectoryReader(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mload_data()\n\u001b[1;32m----> 2\u001b[0m index \u001b[39m=\u001b[39m GPTSimpleVectorIndex\u001b[39m.\u001b[39;49mfrom_documents(documents)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\base.py:100\u001b[0m, in \u001b[0;36mBaseGPTIndex.from_documents\u001b[1;34m(cls, documents, docstore, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     docstore\u001b[39m.\u001b[39mset_document_hash(doc\u001b[39m.\u001b[39mget_doc_id(), doc\u001b[39m.\u001b[39mget_doc_hash())\n\u001b[0;32m     98\u001b[0m nodes \u001b[39m=\u001b[39m service_context\u001b[39m.\u001b[39mnode_parser\u001b[39m.\u001b[39mget_nodes_from_documents(documents)\n\u001b[1;32m--> 100\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m    101\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m    102\u001b[0m     docstore\u001b[39m=\u001b[39;49mdocstore,\n\u001b[0;32m    103\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m    104\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    105\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\vector_store\\vector_indices.py:94\u001b[0m, in \u001b[0;36mGPTSimpleVectorIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, text_qa_template, simple_vector_store_data_dict, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     simple_vector_store_data_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m     87\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39membedding_dict\u001b[39m\u001b[39m\"\u001b[39m: index_struct\u001b[39m.\u001b[39membeddings_dict,\n\u001b[0;32m     88\u001b[0m     }\n\u001b[0;32m     90\u001b[0m vector_store \u001b[39m=\u001b[39m SimpleVectorStore(\n\u001b[0;32m     91\u001b[0m     simple_vector_store_data_dict\u001b[39m=\u001b[39msimple_vector_store_data_dict\n\u001b[0;32m     92\u001b[0m )\n\u001b[1;32m---> 94\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     95\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m     96\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[0;32m     97\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m     98\u001b[0m     text_qa_template\u001b[39m=\u001b[39;49mtext_qa_template,\n\u001b[0;32m     99\u001b[0m     vector_store\u001b[39m=\u001b[39;49mvector_store,\n\u001b[0;32m    100\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m \u001b[39m# TODO: Temporary hack to also store embeddings in index_struct\u001b[39;00m\n\u001b[0;32m    104\u001b[0m embedding_dict \u001b[39m=\u001b[39m vector_store\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39membedding_dict\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:58\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, text_qa_template, vector_store, use_async, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_qa_template \u001b[39m=\u001b[39m text_qa_template \u001b[39mor\u001b[39;00m DEFAULT_TEXT_QA_PROMPT\n\u001b[0;32m     57\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[1;32m---> 58\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     59\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m     60\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[0;32m     61\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m     62\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     63\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\base.py:69\u001b[0m, in \u001b[0;36mBaseGPTIndex.__init__\u001b[1;34m(self, nodes, index_struct, docstore, service_context)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[39massert\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(nodes)\n\u001b[0;32m     70\u001b[0m     \u001b[39m# if not isinstance(index_struct, self.index_struct_cls):\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[39m#     raise ValueError(\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[39m#         f\"index_struct must be of type {self.index_struct_cls} \"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[39m#         f\"but got {type(index_struct)}\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[39m#     )\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\token_counter\\token_counter.py:78\u001b[0m, in \u001b[0;36mllm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_llm_predict\u001b[39m(_self: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     77\u001b[0m     \u001b[39mwith\u001b[39;00m wrapper_logic(_self):\n\u001b[1;32m---> 78\u001b[0m         f_return_val \u001b[39m=\u001b[39m f(_self, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m f_return_val\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:214\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39m@llm_token_counter\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbuild_index_from_nodes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_index_from_nodes\u001b[39m(\u001b[39mself\u001b[39m, nodes: Sequence[Node]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IndexDict:\n\u001b[0;32m    208\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build the index from nodes.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[39m    NOTE: Overrides BaseGPTIndex.build_index_from_nodes.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39m        GPTVectorStoreIndex only stores nodes in document store\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[39m        if vector store does not store text\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:203\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    201\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(index_struct, nodes)\n\u001b[0;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:182\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_add_nodes_to_index\u001b[39m(\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    178\u001b[0m     index_struct: IndexDict,\n\u001b[0;32m    179\u001b[0m     nodes: Sequence[Node],\n\u001b[0;32m    180\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Add document to index.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     embedding_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_embedding_results(\n\u001b[0;32m    183\u001b[0m         nodes,\n\u001b[0;32m    184\u001b[0m         \u001b[39mset\u001b[39;49m(),\n\u001b[0;32m    185\u001b[0m     )\n\u001b[0;32m    187\u001b[0m     new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39madd(embedding_results)\n\u001b[0;32m    189\u001b[0m     \u001b[39m# if the vector store doesn't store text, we need to add the nodes to the\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     \u001b[39m# index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:100\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex._get_node_embedding_results\u001b[1;34m(self, nodes, existing_node_ids)\u001b[0m\n\u001b[0;32m     94\u001b[0m     id_to_node_map[new_id] \u001b[39m=\u001b[39m n\n\u001b[0;32m     96\u001b[0m \u001b[39m# call embedding model to get embeddings\u001b[39;00m\n\u001b[0;32m     97\u001b[0m (\n\u001b[0;32m     98\u001b[0m     result_ids,\n\u001b[0;32m     99\u001b[0m     result_embeddings,\n\u001b[1;32m--> 100\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model\u001b[39m.\u001b[39;49mget_queued_text_embeddings()\n\u001b[0;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result_ids, result_embeddings):\n\u001b[0;32m    102\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\embeddings\\base.py:151\u001b[0m, in \u001b[0;36mBaseEmbedding.get_queued_text_embeddings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m cur_batch_ids \u001b[39m=\u001b[39m [text_id \u001b[39mfor\u001b[39;00m text_id, _ \u001b[39min\u001b[39;00m cur_batch]\n\u001b[0;32m    150\u001b[0m cur_batch_texts \u001b[39m=\u001b[39m [text \u001b[39mfor\u001b[39;00m _, text \u001b[39min\u001b[39;00m cur_batch]\n\u001b[1;32m--> 151\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch_texts)\n\u001b[0;32m    152\u001b[0m result_ids\u001b[39m.\u001b[39mextend(cur_batch_ids)\n\u001b[0;32m    153\u001b[0m result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\embeddings\\openai.py:261\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid mode, model combination: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    260\u001b[0m     engine \u001b[39m=\u001b[39m _TEXT_MODE_MODEL_DICT[key]\n\u001b[1;32m--> 261\u001b[0m embeddings \u001b[39m=\u001b[39m get_embeddings(texts, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    262\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\tenacity\\__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[0;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[1;31mRetryError\u001b[0m: RetryError[<Future at 0x2c09b504df0 state=finished raised RateLimitError>]"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = GPTSimpleVectorIndex.from_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Samsung Galaxy S23 Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4541 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What are the difference between all the s23 models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The main differences between the Samsung Galaxy S23, S23+, and S23 Ultra are in their display sizes, battery capacities, and camera setups. The S23 has a 6.1-inch (155 mm) display, a 3900 mAh battery, and a 50 MP wide sensor, a 10 MP telephoto sensor, and a 12 MP ultrawide sensor. The S23+ has a 6.6-inch (168 mm) display, a 4700 mAh battery, and the same camera setup as the S23. The S23 Ultra has a 6.8-inch (173 mm) display, a 5000 mAh battery, and a 200 MP wide sensor, two 10 MP telephoto sensors, and a 12 MP ultrawide sensor. Additionally, the S23 Ultra features an integrated S Pen for increased functionality and productivity, and is so bloated that Android 13 uses as much storage as Windows 11.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: COVID-19 Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4203 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"Are there any covid-19 vaccine available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At this time, there are no approved vaccines for COVID-19. However, there are several vaccine candidates that are currently in clinical trials and are being evaluated for safety and efficacy. Additionally, laboratory testing and antibody tests are being developed to help diagnose and monitor the virus.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Geforce 40 Series Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4283 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What are the difference between rtx 4080 vs rtx 4090?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The main differences between the RTX 4080 and RTX 4090 are in their core configurations, clock speeds, memory sizes, and price points. The RTX 4090 has a higher core configuration, clock speeds, and memory size than the RTX 4080, and is priced significantly higher at $1599 compared to the RTX 4080's $1199. The RTX 4090 also features third-generation Ray Tracing Cores, fourth-generation Tensor Cores, and Dual NVENC with 8K 10-bit 60FPS AV1 fixed function hardware encoding, while the RTX 4080 does not. Additionally, the RTX 4090 has a TDP of 450W compared to the RTX 4080's 320W. The RTX 4080 has a 3-slot cooler on the Founders Edition and 4-slots on many AIB models, while the RTX 4090 has a 2-slot cooler on the Founders Edition and 3-slots on many AIB models. It was reported that RTX 4080 sales were weak compared to the RTX 4090, which had sold out during its launch a month earlier. The global cost of living crisis and the RTX 4080's generational pricing increase have been suggested as contributing factors for poor sales numbers.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message='You exceeded your current quota, please check your plan and billing details.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mquery(\u001b[39m'\u001b[39;49m\u001b[39mWho invented covid-19?\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\base.py:244\u001b[0m, in \u001b[0;36mBaseGPTIndex.query\u001b[1;34m(self, query_str, mode, query_transform, use_async, **query_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m query_config \u001b[39m=\u001b[39m QueryConfig(\n\u001b[0;32m    231\u001b[0m     index_struct_type\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct\u001b[39m.\u001b[39mget_type(),\n\u001b[0;32m    232\u001b[0m     query_mode\u001b[39m=\u001b[39mmode_enum,\n\u001b[0;32m    233\u001b[0m     query_kwargs\u001b[39m=\u001b[39mquery_kwargs,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m query_runner \u001b[39m=\u001b[39m QueryRunner(\n\u001b[0;32m    236\u001b[0m     index_struct\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct,\n\u001b[0;32m    237\u001b[0m     service_context\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_service_context,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     use_async\u001b[39m=\u001b[39muse_async,\n\u001b[0;32m    243\u001b[0m )\n\u001b[1;32m--> 244\u001b[0m \u001b[39mreturn\u001b[39;00m query_runner\u001b[39m.\u001b[39;49mquery(query_str)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\query\\query_runner.py:342\u001b[0m, in \u001b[0;36mQueryRunner.query\u001b[1;34m(self, query_str_or_bundle, index_id, level)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run query.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \n\u001b[0;32m    326\u001b[0m \u001b[39mNOTE: Relies on mutual recursion between\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39m    composable graph.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m query_combiner, query_bundle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_query_objects(\n\u001b[0;32m    340\u001b[0m     query_str_or_bundle, index_id\u001b[39m=\u001b[39mindex_id\n\u001b[0;32m    341\u001b[0m )\n\u001b[1;32m--> 342\u001b[0m \u001b[39mreturn\u001b[39;00m query_combiner\u001b[39m.\u001b[39;49mrun(query_bundle, level)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\query\\query_combiner\\base.py:66\u001b[0m, in \u001b[0;36mSingleQueryCombiner.run\u001b[1;34m(self, query_bundle, level)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run query combiner.\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m updated_query_bundle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_update(query_bundle)\n\u001b[1;32m---> 66\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_runner\u001b[39m.\u001b[39;49mquery_transformed(\n\u001b[0;32m     67\u001b[0m     updated_query_bundle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index_struct, level\u001b[39m=\u001b[39;49mlevel\n\u001b[0;32m     68\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\query\\query_runner.py:202\u001b[0m, in \u001b[0;36mQueryRunner.query_transformed\u001b[1;34m(self, query_bundle, index_struct, level)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n\u001b[0;32m    201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     \u001b[39mreturn\u001b[39;00m query_obj\u001b[39m.\u001b[39;49mquery(query_bundle)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\token_counter\\token_counter.py:78\u001b[0m, in \u001b[0;36mllm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_llm_predict\u001b[39m(_self: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     77\u001b[0m     \u001b[39mwith\u001b[39;00m wrapper_logic(_self):\n\u001b[1;32m---> 78\u001b[0m         f_return_val \u001b[39m=\u001b[39m f(_self, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m f_return_val\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\query\\base.py:396\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery.query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[39m# TODO: support include summary\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(query_bundle)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\query\\base.py:382\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery._query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# TODO: remove _query and just use query\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve(query_bundle)\n\u001b[0;32m    383\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msynthesize(query_bundle, nodes)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\query\\base.py:249\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery.retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get list of tuples of node and similarity for response.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[39mFirst part of the tuple is the node.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39mSecond part of tuple is the distance from query to the node.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39mIf not applicable, it's None.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m similarity_tracker \u001b[39m=\u001b[39m SimilarityTracker()\n\u001b[1;32m--> 249\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retrieve(query_bundle, similarity_tracker\u001b[39m=\u001b[39;49msimilarity_tracker)\n\u001b[0;32m    251\u001b[0m postprocess_info \u001b[39m=\u001b[39m {\n\u001b[0;32m    252\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msimilarity_tracker\u001b[39m\u001b[39m\"\u001b[39m: similarity_tracker,\n\u001b[0;32m    253\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mquery_bundle\u001b[39m\u001b[39m\"\u001b[39m: query_bundle,\n\u001b[0;32m    254\u001b[0m }\n\u001b[0;32m    255\u001b[0m \u001b[39mfor\u001b[39;00m node_processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_preprocessors:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\indices\\vector_store\\base_query.py:53\u001b[0m, in \u001b[0;36mGPTVectorStoreIndexQuery._retrieve\u001b[1;34m(self, query_bundle, similarity_tracker)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mis_embedding_query:\n\u001b[0;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m query_bundle\u001b[39m.\u001b[39membedding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         query_bundle\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m (\n\u001b[1;32m---> 53\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model\u001b[39m.\u001b[39;49mget_agg_embedding_from_queries(\n\u001b[0;32m     54\u001b[0m                 query_bundle\u001b[39m.\u001b[39;49membedding_strs\n\u001b[0;32m     55\u001b[0m             )\n\u001b[0;32m     56\u001b[0m         )\n\u001b[0;32m     57\u001b[0m     query_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mquery(\n\u001b[0;32m     58\u001b[0m         query_bundle\u001b[39m.\u001b[39membedding,\n\u001b[0;32m     59\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_similarity_top_k,\n\u001b[0;32m     60\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_doc_ids,\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[39m# TODO: fix function signature of query\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\embeddings\\base.py:79\u001b[0m, in \u001b[0;36mBaseEmbedding.get_agg_embedding_from_queries\u001b[1;34m(self, queries, agg_fn)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_agg_embedding_from_queries\u001b[39m(\n\u001b[0;32m     74\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     75\u001b[0m     queries: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     76\u001b[0m     agg_fn: Optional[Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m     78\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     query_embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_query_embedding(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[0;32m     80\u001b[0m     agg_fn \u001b[39m=\u001b[39m agg_fn \u001b[39mor\u001b[39;00m mean_agg\n\u001b[0;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m agg_fn(query_embeddings)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\embeddings\\base.py:79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_agg_embedding_from_queries\u001b[39m(\n\u001b[0;32m     74\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     75\u001b[0m     queries: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     76\u001b[0m     agg_fn: Optional[Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m     78\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     query_embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_query_embedding(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[0;32m     80\u001b[0m     agg_fn \u001b[39m=\u001b[39m agg_fn \u001b[39mor\u001b[39;00m mean_agg\n\u001b[0;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m agg_fn(query_embeddings)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\embeddings\\base.py:68\u001b[0m, in \u001b[0;36mBaseEmbedding.get_query_embedding\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_query_embedding\u001b[39m(\u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m     67\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get query embedding.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_query_embedding(query)\n\u001b[0;32m     69\u001b[0m     query_tokens_count \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer(query))\n\u001b[0;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_tokens_used \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m query_tokens_count\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\llama_index\\embeddings\\openai.py:223\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_query_embedding\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid mode, model combination: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m     engine \u001b[39m=\u001b[39m _QUERY_MODE_MODEL_DICT[key]\n\u001b[1;32m--> 223\u001b[0m \u001b[39mreturn\u001b[39;00m get_embedding(query, engine\u001b[39m=\u001b[39;49mengine)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\tenacity\\__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[0;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\dev\\lib\\site-packages\\tenacity\\nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = index.query('Who invented covid-19?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.save_to_disk('learning.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
